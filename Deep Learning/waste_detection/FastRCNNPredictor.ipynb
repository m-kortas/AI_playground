{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pycocotools\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import transforms as T\n",
    "import utils\n",
    "from engine import evaluate, train_one_epoch\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "up = path.abspath(path.join(\"FastRCNNPredictor.ipynb\", \"../../../..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = up + \"/mkortas/detect-waste/FastRCNN/\"\n",
    "data_file = up + \"/mkortas/detect-waste/annotations/annotat.csv\"\n",
    "data_folder = up + \"/TACO-master/data/\"\n",
    "model_path = up + \"/mkortas/detect-waste/models/model\"\n",
    "num_classes = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_one_annot(path_to_data_file, filename):\n",
    "    data = pd.read_csv(path_to_data_file)\n",
    "    print(filename)\n",
    "    boxes_array = data[data[\"filename\"] == filename][\n",
    "        [\"xmin\", \"ymin\", \"xmax\", \"ymax\"]\n",
    "    ].values\n",
    "    print(boxes_array)\n",
    "    return boxes_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListOfFiles(dirName):\n",
    "    listOfFile = os.listdir(dirName)\n",
    "    allFiles = list()\n",
    "    for entry in listOfFile:\n",
    "        fullPath = os.path.join(dirName, entry)\n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + getListOfFiles(fullPath)\n",
    "        else:\n",
    "            fullPath = fullPath.replace(data_folder, \"\")\n",
    "            allFiles.append(fullPath)\n",
    "    return allFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, data_file, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        files = getListOfFiles(os.path.join(root))\n",
    "        p = re.compile(\"batch\")\n",
    "        l2 = [s for s in files if p.match(s)]\n",
    "        self.imgs = sorted(l2)\n",
    "        self.path_to_data_file = data_file\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root, self.imgs[idx])\n",
    "        self.imgs[idx] = self.imgs[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        box_list = parse_one_annot(self.path_to_data_file, self.imgs[idx])\n",
    "        boxes = torch.as_tensor(box_list, dtype=torch.float32)\n",
    "        num_objs = len(box_list)\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(root=data_folder, data_file=data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(\n",
    "    root=data_folder, data_file=data_file, transforms=get_transform(train=True)\n",
    ")\n",
    "dataset_test = Dataset(\n",
    "    root=data_folder, data_file=data_file, transforms=get_transform(train=False)\n",
    ")\n",
    "\n",
    "torch.manual_seed(1)\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "testing_num = int(len(dataset) * 0.2)\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-testing_num])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-testing_num:])\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=2, shuffle=True, num_workers=4, collate_fn=utils.collate_fn\n",
    ")\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    collate_fn=utils.collate_fn,\n",
    ")\n",
    "print(\n",
    "    \"We have: {} examples, {} are training and {} testing\".format(\n",
    "        len(indices), len(dataset), len(dataset_test)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = get_model(num_classes)\n",
    "model.to(device)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "    lr_scheduler.step()\n",
    "    evaluate(model, data_loader_test, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = get_model(num_classes=num_classes)\n",
    "loaded_model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "img, _ = dataset_test[idx]\n",
    "label_boxes = np.array(dataset_test[idx][1][\"boxes\"])\n",
    "loaded_model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = loaded_model([img])\n",
    "image = Image.fromarray(img.mul(255).permute(1, 2, 0).byte().numpy())\n",
    "draw = ImageDraw.Draw(image)\n",
    "for elem in range(len(label_boxes)):\n",
    "    draw.rectangle(\n",
    "        [\n",
    "            (label_boxes[elem][0], label_boxes[elem][1]),\n",
    "            (label_boxes[elem][2], label_boxes[elem][3]),\n",
    "        ],\n",
    "        outline=\"green\",\n",
    "        width=3,\n",
    "    )\n",
    "for element in range(len(prediction[0][\"boxes\"])):\n",
    "    boxes = prediction[0][\"boxes\"][element].cpu().numpy()\n",
    "    score = np.round(prediction[0][\"scores\"][element].cpu().numpy(), decimals=4)\n",
    "    if score > 0.8:\n",
    "        draw.rectangle(\n",
    "            [(boxes[0], boxes[1]), (boxes[2], boxes[3])], outline=\"red\", width=3\n",
    "        )\n",
    "        draw.text((boxes[0], boxes[1]), text=str(score))\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
